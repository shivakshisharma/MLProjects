{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivakshisharma/MLProjects/blob/main/Gradio_UI_for_Coatedpred.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsOva7uiuuxm",
        "outputId": "1cbe57a2-5d68-41a2-e914-5cfa13a12eea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade -q \"httpx==0.24.1\" \"gradio==3.41.0\" \"scikit-learn==1.2.2\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmJOuyiLw0st",
        "outputId": "c46a0cdb-02aa-47a0-8a5f-d806978d324b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "1xZSCvEFw1vx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model to disk\n",
        "    # filename = 'finalized_model.sav'\n",
        "    # pickle.dump(model, open(filename, 'wb'))\n",
        "\n",
        "def dt1(grade, x3, x4, x5, x6):\n",
        "    x1=0\n",
        "    x2=0\n",
        "    if grade==\"Grade 1\" : x1=1\n",
        "    if grade==\"Grade 2\" : x2=1\n",
        "\n",
        "    X = pd.DataFrame([[x1, x2, x3, x4, x5, x6]], columns = ['Grade 1', 'Grade 2', 'CCM REDUCTION', 'SPM ELONG ACT.', 'RCS TEMP','SS TEMP ACT.'])\n",
        "    with open(\"/content/drive/MyDrive/my_data/Model_rf_output1.pickle\", \"rb\") as f:\n",
        "       model_rf_output1 = pickle.load(f)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/my_data/Model_rf_output2.pickle\", \"rb\") as f:\n",
        "       model_rf_output2 = pickle.load(f)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/my_data/Model_rf_output3.pickle\", \"rb\") as f:\n",
        "       model_rf_output3 = pickle.load(f)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/my_data/Model_rf_output4.pickle\", \"rb\") as f:\n",
        "       model_rf_output4 = pickle.load(f)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/my_data/Model_rf_output5.pickle\", \"rb\") as f:\n",
        "       model_rf_output5 = pickle.load(f)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/my_data/Model_dt_output1.pickle\", \"rb\") as f:\n",
        "       model_dt_output1 = pickle.load(f)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/my_data/Model_dt_output2.pickle\", \"rb\") as f:\n",
        "       model_dt_output2 = pickle.load(f)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/my_data/Model_dt_output3.pickle\", \"rb\") as f:\n",
        "       model_dt_output3 = pickle.load(f)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/my_data/Model_dt_output4.pickle\", \"rb\") as f:\n",
        "       model_dt_output4 = pickle.load(f)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/my_data/Model_dt_output5.pickle\", \"rb\") as f:\n",
        "       model_dt_output5 = pickle.load(f)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/my_data/Model_gb_output1.pickle\", \"rb\") as f:\n",
        "       model_gb_output1 = pickle.load(f)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/my_data/Model_gb_output2.pickle\", \"rb\") as f:\n",
        "       model_gb_output2 = pickle.load(f)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/my_data/Model_gb_output3.pickle\", \"rb\") as f:\n",
        "       model_gb_output3 = pickle.load(f)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/my_data/Model_gb_output4.pickle\", \"rb\") as f:\n",
        "       model_gb_output4 = pickle.load(f)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/my_data/Model_gb_output5.pickle\", \"rb\") as f:\n",
        "       model_gb_output5 = pickle.load(f)\n",
        "    # print(model_rf_final)\n",
        "    y_pred_rf_output1 = model_rf_output1.predict(X)\n",
        "    y_pred_rf_output2 = model_rf_output2.predict(X)\n",
        "    y_pred_rf_output3 = model_rf_output3.predict(X)\n",
        "    y_pred_rf_output4 = model_rf_output4.predict(X)\n",
        "    y_pred_rf_output5 = model_rf_output5.predict(X)\n",
        "\n",
        "    y_pred_dt_output1 = model_dt_output1.predict(X)\n",
        "    y_pred_dt_output2 = model_dt_output2.predict(X)\n",
        "    y_pred_dt_output3 = model_dt_output3.predict(X)\n",
        "    y_pred_dt_output4 = model_dt_output4.predict(X)\n",
        "    y_pred_dt_output5 = model_dt_output5.predict(X)\n",
        "\n",
        "    y_pred_gb_output1 = model_gb_output1.predict(X)\n",
        "    y_pred_gb_output2 = model_gb_output2.predict(X)\n",
        "    y_pred_gb_output3 = model_gb_output3.predict(X)\n",
        "    y_pred_gb_output4 = model_gb_output4.predict(X)\n",
        "    y_pred_gb_output5 = model_gb_output5.predict(X)\n",
        "    return f\"{y_pred_rf_output1[0]:.2f}\", f\"{y_pred_rf_output2[0]:.2f}\", f\"{y_pred_rf_output3[0]:.2f}\", f\"{y_pred_rf_output4[0]:.2f}\", f\"{y_pred_rf_output5[0]:.2f}\", f\"{y_pred_gb_output1[0]:.2f}\", f\"{y_pred_gb_output2[0]:.2f}\", f\"{y_pred_gb_output3[0]:.2f}\", f\"{y_pred_gb_output4[0]:.2f}\", f\"{y_pred_gb_output5[0]:.2f}\", f\"{y_pred_dt_output1[0]:.2f}\", f\"{y_pred_dt_output2[0]:.2f}\", f\"{y_pred_dt_output3[0]:.2f}\", f\"{y_pred_dt_output4[0]:.2f}\", f\"{y_pred_dt_output5[0]:.2f}\"\n"
      ],
      "metadata": {
        "id": "3ACP0AkkwPBI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt1(\"Grade 1\", 80, 0.8, 490, 800)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ_2T-N7wO3h",
        "outputId": "a8e829ac-43dc-42e4-fa23-2af16e93e71c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('23.86',\n",
              " '45.48',\n",
              " '0.23',\n",
              " '166.34',\n",
              " '311.53',\n",
              " '24.06',\n",
              " '45.58',\n",
              " '0.23',\n",
              " '164.91',\n",
              " '311.65',\n",
              " '24.44',\n",
              " '45.21',\n",
              " '0.23',\n",
              " '161.25',\n",
              " '312.72')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "css = \"\"\"\n",
        "#container {\n",
        "    height: 5px;\n",
        "    margin: 0px 0px 35px 40%;\n",
        "    width: 150px;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "## Develops the interface in terms of Blocks in Gradio.\n",
        "with gr.Blocks(css = css) as demo:\n",
        "\n",
        "    ## Adds a row, whatever amount of inputs we take will be placed in that row\n",
        "    with gr.Row():\n",
        "        Grade=  gr.Dropdown(\n",
        "            [\"Grade 1\", \"Grade 2\", \"Grade 3\",\"Grade 4\",\"Grade 5\"], label=\"Grades\", info=\"Add grades\"\n",
        "        )\n",
        "        CCM_REDUCTION = gr.Textbox(label=\"Input for CCM REDUCTION\")\n",
        "        SPM_ELONG_ACT = gr.Textbox(label=\"Input for SPM ELONG ACT.\")\n",
        "        RCS_TEMP = gr.Textbox(label=\"Input for RCS TEMP\")\n",
        "        SS_TEMP = gr.Textbox(label=\"Input for SS TEMP\")\n",
        "\n",
        "    ## Another row. The same protocol\n",
        "    with gr.Row(elem_id=\"container\"):\n",
        "        greet_btn = gr.Button(\"Predict\")\n",
        "\n",
        "    ## In this textbox our Output is displayed.\n",
        "    output_rf_YS = gr.Textbox(label=\"THE UEL (Random Forest)\")\n",
        "    output_rf_UTS = gr.Textbox(label=\"THE EL (Random Forest)\")\n",
        "    output_rf_ELS = gr.Textbox(label=\"THE N10 (Random Forest)\")\n",
        "    output_rf_UEL = gr.Textbox(label=\"THE YS (Random Forest)\")\n",
        "    output_rf_N = gr.Textbox(label=\"THE UTS (Random Forest)\")\n",
        "\n",
        "    output_xgb_YS = gr.Textbox(label=\"THE UEL (XGB)\")\n",
        "    output_xgb_UTS = gr.Textbox(label=\"THE EL (XGB)\")\n",
        "    output_xgb_ELS = gr.Textbox(label=\"THE N10 (XGB)\")\n",
        "    output_xgb_UEL = gr.Textbox(label=\"THE YS (XGB)\")\n",
        "    output_xgb_N = gr.Textbox(label=\"THE  UTS  (XGB)\")\n",
        "\n",
        "    output_dt_YS = gr.Textbox(label=\"THE UEL(Decision Tree)\")\n",
        "    output_dt_UTS = gr.Textbox(label=\"THE EL (Decision Tree)\")\n",
        "    output_dt_ELS = gr.Textbox(label=\"THE  N10 (Decision Tree)\")\n",
        "    output_dt_UEL = gr.Textbox(label=\"THE YS  (Decision Tree)\")\n",
        "    output_dt_N = gr.Textbox(label=\"THE UTS (Decision Tree)\")\n",
        "\n",
        "    outputs_list = [output_rf_YS, output_rf_UTS, output_rf_ELS, output_rf_UEL, output_rf_N, output_xgb_YS, output_xgb_UTS, output_xgb_ELS, output_xgb_UEL, output_xgb_N, output_dt_YS, output_dt_UTS, output_dt_ELS, output_dt_UEL, output_dt_N]\n",
        "\n",
        "    ## Button function. When clicked, it calls our \"model_prediction\" function, takes in inputs and returns the output which is displayed in the \"output\" textbox\n",
        "    greet_btn.click(fn=dt1, inputs=[Grade, CCM_REDUCTION, SPM_ELONG_ACT, RCS_TEMP, SS_TEMP], outputs=outputs_list)\n",
        "\n",
        "\n",
        "## Launches the gradio platform. Setting \"share\" parameter to \"False\" run the gradio in localhost.\n",
        "    demo.launch(share = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "sCTgTXdS1o7Y",
        "outputId": "835c33ca-75d5-44fe-b047-bd821ae6d841"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://631f9515f6943340fd.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://631f9515f6943340fd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install git\n",
        "!git config --global user.email \"shivakshisharma2000@gmail.com\"\n",
        "!git config --global user.name \"shivakshisharma\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23MtoInjTnlo",
        "outputId": "38205c99-0ed9-46ce-856a-cd131f7e9ec9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.10).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Js23qH-iwdqS"
      }
    }
  ]
}